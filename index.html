<!DOCTYPE html>
<html>
<head>

<link rel='stylesheet' href='https://use.fontawesome.com/releases/v5.7.0/css/all.css' integrity='sha384-lZN37f5QGtY3VHgisS14W3ExzMWZxybE1SJSEsQp9S+oqd12jhcu+A56Ebc1zFSJ' crossorigin='anonymous'>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<meta name="keywords" charset="UTF-8" content="Bao Xin Chen, Bao Chen, Robot Vision, Person Following Robot" />
<div id="thisdiv">
<table style="width:800px">
<tr>
<td>
<a href="./images.html"><img src="./images/baoxinchen.jpg" alt="bao xin chen" style="width:210px;height:150px;"><i class="fa fa-hand-o-up" style="font-size:10px"></i></a>
</td>
<td>
<h1>Bao Xin Chen 陈宝新</h1>
<h3>Master's student <i class='fas fa-at'></i> <a href="http://www.yorku.ca" target="_blank">York University</a>, Toronto, Canada</br></h3>
<table>
<tr><td><i class='fas fa-envelope' style='font-size:16px'></i></td><td>baox[last name][at]cse[dot]yorku[dot]ca</td></tr>
<tr><td><i class='fas fa-envelope' style='font-size:16px'></i></td><td>baoxin[dot][last name][at]outlook[dot]com</td></tr>
<tr><td><i class='fas fa-passport' style='font-size:16px'></i></td><td>Country of Citizenship: Canada <i class='fab fa-canadian-maple-leaf' style='font-size:16px'></i></td></tr>
</table>
</br>
</td>
</tr>
</table>
</div>
</head>
<body>
<div id="thisdiv">


</br>
</br>



<table style="width:800px">
<tr><i><b><i class="fa fa-address-card" style="font-size:16px"></i> <u>About Me:</u></b></i></tr>
<tr>
<td>
<p>Currently, I am a Master's student in <a href="http://jtl.lassonde.yorku.ca/" target="_blank">Professor John K. Tsotsos' Lab</a> at <a href="http://eecs.lassonde.yorku.ca/" target="_blank">York University Electrical Engineering and Computer Science (EECS)</a> department (2016 - 2019). Previously, I was an undergrad student in <a href="https://www.utoronto.ca/" target="_blank">University of Toronto</a> computer science department. My focus was on Machine Learning and Computer Vision (2012 - 2016). My current research interest is in <b>Robot Vision</b> (real-time computer vision and machine learning applications on mobile platforms) and I am open for <b>project collaborations</b> (no limited to object detection/segmentation, object tracking, image classification, robot control, navigation, autonomous vehicle related projects, etc).</p></br>
<table style="margin-left:auto; margin-right:auto;"><tr>
<td><a href="cv.pdf" target="_blank"><img src="./images/icon_cv.png" alt="CV" style="height:28px; vertical-align: bottom;"></a></td>
<td><a href="transcriptUT.pdf" target="_blank"><img src="./images/icon_transcript_uoft2.png" alt="TranscriptUofT" style="height:28px; vertical-align: bottom;"></a></td>
<td><a href="transcriptYU.pdf" target="_blank"><img src="./images/icon_transcript_yorku2.png" alt="TranscriptYorkU" style="height:28px; vertical-align: bottom;"></a></td>
<td><a href="https://www.linkedin.com/in/baoxinchen" target="_blank"><i class="fa fa-linkedin-square" style="font-size:33px; vertical-align: bottom;"></i></a></td>
<td><a href="https://www.youtube.com/channel/UCe4C3FN8R0iWdbt3hEoNJfQ/playlists" target="_blank"><i class="fa fa-youtube-square" style="font-size:33px; vertical-align: bottom;"></i></a></td>
<td><a href="https://github.com/salemchen" target="_blank"><i class="fa fa-github-square" style="font-size:33px; vertical-align: bottom;"></i></a></td>
<td><a href="https://www.researchgate.net/profile/Bao_Xin_Chen" target="_blank"><i class='fab fa-researchgate' style='font-size:32px; vertical-align: bottom;'></i></a></td>
<td><a href="https://scholar.google.ca/citations?user=CgtuYXcAAAAJ&hl=en" target="_blank"><i class="fas fa-user-graduate" style="font-size:30px; vertical-align: bottom;"></i></a></td>

<!--
<td><a href="https://www.facebook.com/baochen2008" target="_blank"><i class="fa fa-facebook-square" style="font-size:24px"></i></a></td>
<td><a href="https://twitter.com/BaoXinChen" target="_blank"><i class="fa fa-twitter-square" style="font-size:24px"></i></a></td>
-->
</tr></table>
</td>
</tr>
</table>


</br>
</br>



<table style="width:800px">
<tr><a href="publications.html"><i><b><i class='fas fa-book-open' style='font-size:16px'></i> <u>Publications:</u></b></i></a></tr>

<tr>
<td style="width:100px;height:100px;"><img src="./images/paper6.jpg" alt="Visual Object Tracking" style="width:100px;height:100px;"></td>
<td>
<b>Bao Xin Chen</b> and <a href="http://www.cse.yorku.ca/~tsotsos" target="_blank">John K. Tsotsos</a></br>
"<a href="https://arxiv.org/abs/1907.03892" target="_blank"><b>Fast Visual Object Tracking with Rotated Bounding Boxes</b></a>"</br>
2019</br>
<i class="fa fa-hand-o-right" style="font-size:16px"></i> <a href="https://arxiv.org/abs/1907.03892" target="_blank">[arXiv]</a><a href="./publications/fastVOT_arXiv_2019_citation.txt" target="_blank">[cite]</a><a href="https://github.com/salemchen/siammask_e" target="_blank">[code]</a> TBA:[project page]
</td>
</tr>
<tr>
<td colspan="2" style="height:20px;">
</td>
</tr>

<tr>
<td style="width:100px;height:100px;"><img src="./images/paper5.png" alt="Distributed Learning" style="width:100px;height:100px;"></td>
<td>
<a href="http://www.cse.yorku.ca/~xingzhao/" target="_blank">Xing Zhao</a>, <a href="http://www.cse.yorku.ca/~aan/" target="_blank">Aijun An</a>, Junfeng Liu, and <b>Bao Xin Chen</b></br>
"<a href="./publications/DSSP_ICDCS_2019.pdf" target="_blank"><b>Dynamic Stale Synchronous Parallel Distributed Training for Deep Learning</b></a>"</br>
in <a href="https://theory.utdallas.edu/ICDCS2019/" target="_blank">39th International Conference on Distributed Computing Systems (ICDCS) 2019</a>.</br>
<i class="fa fa-info-circle" style="font-size:16px"></i> <b>Oral</b></br>
<i class="fa fa-hand-o-right" style="font-size:16px"></i> <a href="./publications/DSSP_ICDCS_2019.pdf" target="_blank">[paper]</a><a href="./publications/DSSP_icdcs-2019_citation.txt" target="_blank">[cite]</a>
</td>
</tr>
<tr>
<td colspan="2" style="height:20px;">
</td>
</tr>

<tr>
<td style="width:100px;height:100px;"><a href="http://jtl.lassonde.yorku.ca/2018/04/scene-classification-robots/" target="_blank"><img src="./images/paper4.png" alt="Words" style="width:100px;height:100px;"></a></td>
<td>
<b>Bao Xin Chen</b>, <a href="http://www.raghavendersahdev.com/" target="_blank">Raghavender Sahdev</a>, Dekun Wu, <a href="http://www.cse.yorku.ca/~xingzhao/" target="_blank">Xing Zhao</a>, <a href="https://www.eecs.yorku.ca/~papaggel/" target="_blank">Manos Papagelis</a>, and <a href="http://www.cse.yorku.ca/~tsotsos" target="_blank">John K. Tsotsos</a></br>
"<a href="https://natanaso.github.io/rcw-icra18/assets/ref/ICRA-MRP18_paper_25.pdf" target="_blank"><b>Scene Classification in Indoor Environments for Robots using Word Embeddings</b></a>"</br>
in <a href="https://natanaso.github.io/rcw-icra18/" target="_blank">ICRA Workshop on Multimodal Robot Perception, 2018</a>.</br>
<i class="fa fa-info-circle" style="font-size:16px"></i> Poster</br>
<i class="fa fa-hand-o-right" style="font-size:16px"></i> <a href="http://jtl.lassonde.yorku.ca/2018/04/scene-classification-robots/" target="_blank">[project page]</a><a href="https://www.youtube.com/playlist?list=PL_PLOWFkDLAYi8WQzvlWuVtNuUAGmHMpu" target="_blank">[videos]</a><a href="https://natanaso.github.io/rcw-icra18/assets/ref/ICRA-MRP18_paper_25.pdf" target="_blank">[paper]</a><a href="./publications/scene_classification_using_word_embedding_icra-2018workshop_citation.txt" target="_blank">[cite]</a>
</td>
<tr>
<td colspan="2" style="height:20px;">
</td>
</tr>

<tr>
<td style="width:100px;height:100px;"><a href="http://jtl.lassonde.yorku.ca/2018/02/localization-among-humans/" target="_blank"><img src="./images/paper3.png" alt="Robot" style="width:100px;height:100px;"></a></td>
<td>
<a href="http://www.raghavendersahdev.com/" target="_blank">Raghavender Sahdev</a>, <b>Bao Xin Chen</b>,  and <a href="http://www.cse.yorku.ca/~tsotsos" target="_blank">John K. Tsotsos</a></br>
"<a href="https://www.raghavendersahdev.com/uploads/3/9/6/2/39623741/localization_among_humans_crv-2018.pdf" target="_blank"><b>Indoor Localization in Dynamic Human Environments using Visual Odometry and Global Pose Refinement</b></a>"</br>
in <i>Computer and Robot Vision (CRV), 2018 15th Conference on</i>, IEEE, 2018, pp. 360-367.</br>
<i class="fa fa-info-circle" style="font-size:16px"></i> Poster</br>
<i class="fa fa-hand-o-right" style="font-size:16px"></i> <a href="http://jtl.lassonde.yorku.ca/2018/02/localization-among-humans/" target="_blank">[project page]</a><a href="https://www.raghavendersahdev.com/uploads/3/9/6/2/39623741/localization_among_humans_crv-2018.pdf" target="_blank">[paper]</a><a href="./publications/localization_among_humans_crv-2018_citation.txt" target="_blank">[cite]</a>
</td>
</tr>
<tr>
<td colspan="2" style="height:20px;">
</td>
</tr>

<tr>
<td style="width:100px;height:100px;"><a href="http://jtl.lassonde.yorku.ca/2017/05/person-following-cnn/" target="_blank"><img src="./images/paper2.png" alt="Robot" style="width:90px;height:100px;"></a></td>
<td>
<b>Bao Xin Chen*</b>, <a href="http://www.raghavendersahdev.com/" target="_blank">Raghavender Sahdev*</a>, and <a href="http://www.cse.yorku.ca/~tsotsos" target="_blank">John K. Tsotsos</a></br>
"<a href="http://jtl.lassonde.yorku.ca/wp-content/uploads/2017/05/personfollowingrobotcnn_icvs2017.pdf" target="_blank"><b>Integrating Stereo Vision with a CNN Tracker for a Person-Following Robot</b></a>"</br>
in <i>11th International Conference on Computer Vision Systems (ICVS)</i>, Springer, 2017, pp. 300-313.</br>
<i class="fa fa-info-circle" style="font-size:16px"></i> <b>Oral</b> (in highlighted section)</br>
<i class='fas fa-award' style='font-size:16px'></i> Received <a href="http://icvs2017.ram-lab.com/program/awards/" target="_blank"><b>Best Paper Finalist</b></a> award at <a href="http://icvs2017.ram-lab.com/" target="_blank">ICVS 2017</a>, Shenzhen, China</br>
<i class="fa fa-hand-o-right" style="font-size:16px"></i> <a href="http://jtl.lassonde.yorku.ca/2017/05/person-following-cnn/" target="_blank">[project page]</a><a href="https://www.youtube.com/playlist?list=PL_PLOWFkDLAaWp7P3IEgyoyreIa8sFIIW" target="_blank">[videos]</a><a href="http://jtl.lassonde.yorku.ca/wp-content/uploads/2017/05/personfollowingrobotcnn_icvs2017.pdf" target="_blank">[paper]</a><a href="./publications/person_following_robot_icvs-2017_citation.txt" target="_blank">[cite]</a>
</td>
</tr>
<tr>
<td colspan="2" style="height:20px;">
</td>
</tr>

<tr>
<td style="width:100px;height:100px;"><a href="http://jtl.lassonde.yorku.ca/2017/02/person-following/"><img src="./images/paper1.png" alt="Robot" style="width:100px;height:100px;" target="_blank"></a></td>
<td>
<b>Bao Xin Chen*</b>, <a href="http://www.raghavendersahdev.com/" target="_blank">Raghavender Sahdev*</a>, and <a href="http://www.cse.yorku.ca/~tsotsos" target="_blank">John K. Tsotsos</a></br>
"<a href="http://jtl.lassonde.yorku.ca/wp-content/uploads/2017/02/pfr_paper_crv2017.pdf" target="_blank"><b>Person Following Robot Using Selected Online Ada-Boosting with Stereo Camera</b></a>"</br>
in <i>Computer and Robot Vision (CRV), 2017 14th Conference on</i>, IEEE, 2017, pp. 48-55.</br>
<i class="fa fa-info-circle" style="font-size:16px"></i> <b>Oral</b></br>
<i class='fas fa-award' style='font-size:16px'></i> Received <a href="http://www.cipprs.org/CRV_bestpaper_award.html" target="_blank"><b>Best Robotics Paper</b></a> award at <a href="http://aigicrv.org/2017/" target="_blank">AI-GI-CRV 2017</a>, Edmonton, Canada</br>
<i class="fa fa-hand-o-right" style="font-size:16px"></i> <a href="http://jtl.lassonde.yorku.ca/2017/02/person-following/" target="_blank">[project page]</a><a href="http://jtl.lassonde.yorku.ca/wp-content/uploads/2017/02/pfr_paper_crv2017.pdf" target="_blank">[paper]</a><a href="./publications/person_following_robot_crv-2017_citation.txt" target="_blank">[cite]</a>
</td>
</tr>
<tr>
<td colspan="2" style="height:20px;">
</td>
</tr>

<tr>
<td colspan="2">
* denote as equal contribution
</td>
</tr>

</table>


</br>
</br>



<table style="width:800px">
<tr><i><b><i class='fas fa-newspaper' style='font-size:16px'></i> <u>Activities:</u></b></i></tr>

<tr valign="top">
<td>
&#8921;
</td>
<td><p>July 15th, 2019, published a new state-of-the-art <a href="https://arxiv.org/abs/1907.03892" target="_blank">object tracking algorithm</a> for datasets with rotated bounding boxes (VOT2015-2019). And, code is available <a href="https://github.com/salemchen/siammask_e" target="_blank">here</a>.</p>
</td>
</tr>
<tr style="height:5px;">
</tr>

<tr valign="top">
<td>
&#8921;
</td>
<td><p>June 7th, 2018, I presented a poster at NCFRN AGM 2018 in Montreal, Quebec.</p>
</td>
</tr>
<tr style="height:5px;">
</tr>

<tr valign="top">
<td>
&#8921;
</td>
<td><p>May 21th, 2018, my paper "Scene Classification in Indoor Environments for Robots using Word Embeddings" appeared at ICRA 2018 Workshop: Representing a Complex World in Brisbane, Australia.</p>
</td> 
</tr>
<tr style="height:5px;">
</tr>

<tr valign="top">
<td>
&#8921;
</td>
<td><p>May 10th, 2018, my paper "Indoor Localization in Dynamic Human Environments using Visual Odometry and Global Pose Refinement" appeared at the 15th Conference on Computer and Robot Vision (CRV 2018) in Toronto, Canada.</p>
</td> 
</tr>
<tr style="height:5px;">
</tr>

<tr valign="top">
<td>
&#8921;
</td>
<td><p>May 8th-11th, 2018, volunteered at <a href="http://aigicrv.org/2018/" target="_blank">AI-GI-CRV 2018</a> in Toronto, Canada.</p>
</td> 
</tr>
<tr style="height:5px;">
</tr>

<tr valign="top">
<td>
&#8921;
</td>
<td><p>May 3th, 2018, one paper accepted by <a href="https://natanaso.github.io/rcw-icra18/" target="_blank">ICRA 2018 Workshop: Representing a Complex World</a>.</p>
</td> 
</tr>
<tr style="height:5px;">
</tr>

<tr valign="top">
<td>
&#8921;
</td>
<td><p>July 10th, 2017, orally presented my paper "Integrating Stereo Vision with a CNN Tracker for a Person-Following Robot" at the 11th International Conference on Computer Vision System (ICVS 2017), Shenzhen, China (Shenzhen is a city near my hometown Taishan).</p>
</td> 
</tr>
<tr style="height:5px;">
</tr>

<tr valign="top">
<td>
&#8921;
</td>
<td><p>June 13th, 2017, presented a poster at York University CVR & VISTA Internatinal Conference on Vision in the Real World, Toronto, Ontario.</p>
</td>
</tr>
<tr style="height:5px;">
</tr>

<tr valign="top">
<td>
&#8921;
</td>
<td><p>May 19th, 2017, orally presented my paper "Person Following Robot Using Selected Online Ada-Boosting with Stereo Camera" at the 14th Conference on Computer and Robot Vision (CRV 2017), Edmonton, Alberta.</p>
</td>
</tr>
<tr style="height:5px;">
</tr>

<tr valign="top">
<td>
&#8921;
</td>
<td><p>May 1st, 2017, presented two posters at NSERC Canadian Field Robotics Network (NCFRN), Ottawa, Ontario. Our work was covered by  Discovery, the Globe and mail.</p>
</td>
</tr>

</table>


</br>
</br>



<table style="width:800px">
<tr><i><b><i class='fas fa-award' style='font-size:16px'></i> <u>Awards:</u></b></i></tr>

<tr><td></td><td><i>Graduate:</i></td></tr>

<tr valign="top">
<td>
&#8921;
</td>
<td><p>Queen Elizabeth II Graduate Scholarships in Science & Technology (York University) - offered: CAD $15,000 (2019 - 2020, I rejected).</p>
</td>
</tr>
<tr style="height:5px;">
</tr>

<tr valign="top">
<td>
&#8921;
</td>
<td><p>Queen Elizabeth II Graduate Scholarships in Science & Technology (York University) - Total value: CAD $15,000 (2018 Sep - 2019 Aug).</p>
</td>
</tr>
<tr style="height:5px;">
</tr>

<tr valign="top">
<td>
&#8921;
</td>
<td><p><a href="http://icvs2017.ram-lab.com/program/awards/" target="_blank"><b>Best Paper Finalist</b></a> award at <a href="http://icvs2017.ram-lab.com/" target="_blank">ICVS 2017</a>, Shenzhen, China</p>
</td>
</tr>
<tr style="height:5px;">
</tr>

<tr valign="top">
<td>
&#8921;
</td>
<td><p><a href="http://www.cipprs.org/CRV_bestpaper_award.html" target="_blank"><b>Best Robotics Paper</b></a> award at <a href="http://aigicrv.org/2017/" target="_blank">AI-GI-CRV 2017</a>, Edmonton, Canada</p>
</td>
</tr>
<tr style="height:5px;">
</tr>

<tr valign="top">
<td>
&#8921;
</td>
<td><p><a href="http://www.yorku.ca/" target="_blank">York University</a> Masters Domestic Student Offer funding - Total value: CAD $41,666 (2016 Sep - 2018 Apr).</p>
</td>
</tr>
<tr style="height:5px;">
</tr>

<tr valign="top">
<td>
&#8921;
</td>
<td><p><a href="http://eecs.lassonde.yorku.ca/" target="_blank">Lassonde Graduate</a> Entrance Scholarship (<a href="http://www.yorku.ca/" target="_blank">York University</a>) - Total value: CAD $8,000 (2016 Sep - 2017 Aug).</p>
</td>
</tr>
<tr style="height:5px;">
</tr>

<tr><td></td><td><i>Undergraduate:</i></td></tr>

<tr valign="top">
<td>
&#8921;
</td>
<td><p>Graduated with High Distinction (<a href="https://www.utoronto.ca/" target="_blank">University of Toronto</a>) (2016).</p>
</td>
</tr>
<tr style="height:5px;">
</tr>

<tr valign="top">
<td>
&#8921;
</td>
<td><p>Norma Brock Award (<a href="https://www.utoronto.ca/" target="_blank">University of Toronto</a>) - Total value: CAD $3,000 (2014 & 2015).</p>
</td>
</tr>
<tr style="height:5px;">
</tr>

<tr valign="top">
<td>
&#8921;
</td>
<td><p>Dean's List (<a href="https://www.utoronto.ca/" target="_blank">University of Toronto</a>) (2013-2016).</p>
</td>
</tr>
<tr style="height:5px;">
</tr>

<tr><td></td><td><i>High School:</i></td></tr>

<tr valign="top">
<td>
&#8921;
</td>
<td><p>Ontario Principal's Award (2012).</p>
</td>
</tr>

</table>


</br>
</br>
</div>

</body>
</html>
<style type="text/css">
a:link {
	color: black;
	text-decoration: none;
}

a:hover {
    text-decoration: underline;
}

a:visited {
    color: black;
}

a:active {
    color: black;
}

p {
    text-align: justify;
    margin: 0px 0px 0px 0px;
}

#thisdiv {
  max-width: 800px;
  margin: 0 auto;
}

table, th, td {
  //border: 1px solid black;
}
</style>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-98720199-1', 'auto');
  ga('send', 'pageview');

</script>
